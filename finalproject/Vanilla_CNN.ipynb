{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nb\n",
    "from nilearn import image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'logs/basic_qc_cnn/592018', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f173439e208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "<TensorSliceDataset shapes: ((),), types: (tf.string,)>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"Shape:0\", shape=(5,), dtype=int32)\n",
      "Tensor(\"Shape_1:0\", shape=(5,), dtype=int32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from logs/basic_qc_cnn/592018/model.ckpt-14677\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 14678 into logs/basic_qc_cnn/592018/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 14677\n"
     ]
    }
   ],
   "source": [
    "from source_code.data_io import Dataset_Pipeline, _get_data\n",
    "\n",
    "devices = ['/gpu:0', '/gpu:1']\n",
    "\n",
    "class_type=True #true if QC, false if site\n",
    "\n",
    "if class_type:\n",
    "    import source_code.models.basic_qc_cnn as model\n",
    "    train_cache_prefix=\"/home/smantra/finalproject/cache_train_qc/\"\n",
    "    eval_cache_prefix=\"/home/smantra/finalproject/cache_eval_qc/\"\n",
    "    d = devices[0]\n",
    "else:\n",
    "    import source_code.models.basic_site_cnn as model\n",
    "    train_cache_prefix=\"/home/smantra/finalproject/cache_train_sites/\"\n",
    "    eval_cache_prefix=\"/home/smantra/finalproject/cache_eval_sites/\"\n",
    "    d = devices[1]\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    log_dir = \"logs\"\n",
    "    current_run_subdir = os.path.join(\n",
    "        \"run_\" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "#    model_dir = os.path.join(log_dir, model.name, \"106x128x110\")#current_run_subdir)\n",
    "    model_dir = os.path.join(log_dir, model.name, '592018')\n",
    "\n",
    "    run_config = tf.estimator.RunConfig(model_dir=model_dir)\n",
    "\n",
    "    params = tf.contrib.training.HParams(\n",
    "        target_shape=(106, 128, 110),\n",
    "        model_dir=model_dir\n",
    "    )\n",
    "\n",
    "    ds = Dataset_Pipeline(target_shape=params.target_shape,\n",
    "                          n_epochs=10,\n",
    "                          train_src_folder=\"/home/smantra/finalproject/data/\",\n",
    "                          train_cache_prefix=\"/home/smantra/finalproject/cache_train/\",\n",
    "                          eval_src_folder=\"/home/smantra/finalproject/eval/\",\n",
    "                          eval_cache_prefix=\"/home/smantra/finalproject/cache_eval/\",\n",
    "                          batch_size=4\n",
    "                         )\n",
    "\n",
    "    # Workaround for cache iterator concurency issues. Iterate over the whole\n",
    "    # training dataset without counterbalancing to make sure everything is\n",
    "    # preprocessed and cached\n",
    "    if not os.path.exists(ds.train_cache_prefix + \".index\"):\n",
    "        print(\"Preprocessing the training set\")\n",
    "        with tf.Session() as sess:\n",
    "            train_dataset = _get_data(batch_size=ds.batch_size,\n",
    "                                      src_folder=ds.train_src_folder,\n",
    "                                      n_epochs=1,\n",
    "                                      cache_prefix=ds.train_cache_prefix,\n",
    "                                      shuffle=False,\n",
    "                                      target_shape=params.target_shape,\n",
    "                                     )\n",
    "\n",
    "            train_dataset = train_dataset.make_one_shot_iterator()\n",
    "            while True:\n",
    "                try:\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.simplefilter(\"ignore\")\n",
    "                        features, (qc_labels, site_labels) = sess.run(train_dataset.get_next())\n",
    "\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "        print(\"Finished preprocessing the training set\")\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=ds.train_input_fn,\n",
    "                                        max_steps=20000,\n",
    "                                       )\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=ds.eval_input_fn,\n",
    "                                      steps=None,\n",
    "                                      start_delay_secs=0,\n",
    "                                      throttle_secs=600)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(model_fn=model.model_fn,\n",
    "                                       params=params,\n",
    "                                       config=run_config)\n",
    "    \n",
    "    config = tf.ConfigProto() \n",
    "    config.gpu_options.allow_growth = True \n",
    "    with tf.Session(config=config) as sess:\n",
    "        with tf.device(d):\n",
    "            sess.run(tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
