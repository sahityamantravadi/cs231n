{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nb\n",
    "from nilearn import image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import warnings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the training set\n",
      "<TensorSliceDataset shapes: ((),), types: (tf.string,)>\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "ImageFileError: Cannot work out file type of \"/home/smantra/finalproject/data/sub-0050049_T1w.nii.gz\"\nTraceback (most recent call last):\n\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 157, in __call__\n    ret = func(*args)\n\n  File \"/home/smantra/finalproject/src/data_io.py\", line 43, in _read_and_resample\n    nii = nb.load(path_str)\n\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/nibabel/loadsave.py\", line 49, in load\n    filename)\n\nnibabel.filebasedimages.ImageFileError: Cannot work out file type of \"/home/smantra/finalproject/data/sub-0050049_T1w.nii.gz\"\n\n\n\t [[Node: read_and_resample_0 = PyFunc[Tin=[DT_STRING, DT_DOUBLE, DT_INT32], Tout=[DT_FLOAT], token=\"pyfunc_6\"](arg0, read_and_resample_placeholder, read_and_resample_placeholder_1)]]\n\t [[Node: IteratorGetNext_127 = IteratorGetNext[output_shapes=[[?,106,128,110], [?]], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_3)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: ImageFileError: Cannot work out file type of \"/home/smantra/finalproject/data/sub-0050049_T1w.nii.gz\"\nTraceback (most recent call last):\n\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 157, in __call__\n    ret = func(*args)\n\n  File \"/home/smantra/finalproject/src/data_io.py\", line 43, in _read_and_resample\n    nii = nb.load(path_str)\n\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/nibabel/loadsave.py\", line 49, in load\n    filename)\n\nnibabel.filebasedimages.ImageFileError: Cannot work out file type of \"/home/smantra/finalproject/data/sub-0050049_T1w.nii.gz\"\n\n\n\t [[Node: read_and_resample_0 = PyFunc[Tin=[DT_STRING, DT_DOUBLE, DT_INT32], Tout=[DT_FLOAT], token=\"pyfunc_6\"](arg0, read_and_resample_placeholder, read_and_resample_placeholder_1)]]\n\t [[Node: IteratorGetNext_127 = IteratorGetNext[output_shapes=[[?,106,128,110], [?]], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_3)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-740c726eb8f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                         \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: ImageFileError: Cannot work out file type of \"/home/smantra/finalproject/data/sub-0050049_T1w.nii.gz\"\nTraceback (most recent call last):\n\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 157, in __call__\n    ret = func(*args)\n\n  File \"/home/smantra/finalproject/src/data_io.py\", line 43, in _read_and_resample\n    nii = nb.load(path_str)\n\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/nibabel/loadsave.py\", line 49, in load\n    filename)\n\nnibabel.filebasedimages.ImageFileError: Cannot work out file type of \"/home/smantra/finalproject/data/sub-0050049_T1w.nii.gz\"\n\n\n\t [[Node: read_and_resample_0 = PyFunc[Tin=[DT_STRING, DT_DOUBLE, DT_INT32], Tout=[DT_FLOAT], token=\"pyfunc_6\"](arg0, read_and_resample_placeholder, read_and_resample_placeholder_1)]]\n\t [[Node: IteratorGetNext_127 = IteratorGetNext[output_shapes=[[?,106,128,110], [?]], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_3)]]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "import src.models.basic_cnn as model\n",
    "from src.data_io import InputFnFactory, _get_data\n",
    "import datetime\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    log_dir = \"logs\"\n",
    "    current_run_subdir = os.path.join(\n",
    "        \"run_\" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "    model_dir = os.path.join(log_dir, model.name, \"106x128x110\")#current_run_subdir)\n",
    "\n",
    "    run_config = tf.estimator.RunConfig(model_dir=model_dir)\n",
    "\n",
    "    params = tf.contrib.training.HParams(\n",
    "        target_shape=(106, 128, 110),\n",
    "        model_dir=model_dir\n",
    "    )\n",
    "\n",
    "    ds = InputFnFactory(target_shape=params.target_shape,\n",
    "                        n_epochs=100,\n",
    "                        train_src_folder=\"/home/smantra/finalproject/data/\",\n",
    "                        train_cache_prefix=\"/home/smantra/finalproject/cache_train_hires/\",\n",
    "                        eval_src_folder=\"/home/smantra/finalproject/eval/\",\n",
    "                        eval_cache_prefix=\"/home/smantra/finalproject/cache_eval_hires/\",\n",
    "                        batch_size=4\n",
    "                        )\n",
    "\n",
    "    # Workaround for cache iterator concurency issues. Iterate over the whole\n",
    "    # training dataset without counterbalancing to make sure everything is\n",
    "    # preprocessed and cached\n",
    "    if not os.path.exists(ds.train_cache_prefix + \".index\"):\n",
    "        print(\"Preprocessing the training set\")\n",
    "        with tf.Session() as sess:\n",
    "            train_dataset = _get_data(batch_size=ds.batch_size,\n",
    "                                      src_folder=ds.train_src_folder,\n",
    "                                      n_epochs=2,\n",
    "                                      cache_prefix=ds.train_cache_prefix,\n",
    "                                      shuffle=False,\n",
    "                                      target_shape=params.target_shape,\n",
    "                                      balance_dataset=True)\n",
    "\n",
    "            train_dataset = train_dataset.make_one_shot_iterator()\n",
    "            while True:\n",
    "                try:\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.simplefilter(\"ignore\")\n",
    "                        features, labels = sess.run(train_dataset.get_next())\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "        print(\"Finished preprocessing the training set\")\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=ds.train_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=ds.eval_input_fn,\n",
    "                                      steps=None,\n",
    "                                      start_delay_secs=0,\n",
    "                                      throttle_secs=1200)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(model_fn=model.model_fn,\n",
    "                                       params=params,\n",
    "                                       config=run_config)\n",
    "\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
