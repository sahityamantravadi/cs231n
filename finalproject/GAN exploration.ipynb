{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import datetime\n",
    "from glob import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nb\n",
    "from nilearn import image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, a=0.1):\n",
    "    return tf.maximum(a*x, x)\n",
    "\n",
    "def G_conv(batch_input, out_channels):\n",
    "    return tf.layers.conv3d(batch_input, out_channels, kernel_size=4, strides=(2, 2, 2), padding=\"valid\")\n",
    "\n",
    "def D_conv(batch_input, out_channels):\n",
    "    return tf.layers.conv3d(batch_input, out_channels, kernel_size=4, strides=(1, 1, 1), padding=\"same\")\n",
    "\n",
    "def D_max_pool(batch_input):\n",
    "    return tf.layers.max_pooling3d(batch_input, 2, 2)\n",
    "\n",
    "def G_conv_transpose(batch_input, out_channels):\n",
    "    return tf.layers.conv3d_transpose(batch_input, out_channels, kernel_size=4, strides=(2, 2, 2), padding=\"valid\")\n",
    "\n",
    "def batchnorm(batch_input):\n",
    "    return tf.layers.batch_normalization(batch_input, epsilon=1e-5, momentum=0.1, training=True)\n",
    "\n",
    "def generator(G_in, G_out_channels):\n",
    "    with tf.variable_scope(\"generator\"):\n",
    "        layers = []\n",
    "        G_in = tf.expand_dims(G_in, -1)\n",
    "        # encoder_1\n",
    "        with tf.variable_scope(\"encoder_1\"):\n",
    "            conv_out = G_conv(G_in, ngf)\n",
    "\n",
    "    #        output = gen_conv(G_in, ngf)\n",
    "            layers.append(conv_out)\n",
    "\n",
    "        layer_nfilters = [\n",
    "            ngf, # encoder_2\n",
    "            ngf * 2, # encoder_3\n",
    "            ngf * 4, # encoder_4\n",
    "        ]\n",
    "\n",
    "        for out_n in layer_nfilters:\n",
    "            with tf.variable_scope(\"encoder_%d\" % (len(layers) + 1)):\n",
    "                rectified = lrelu(layers[-1], 0.1)\n",
    "                # [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]\n",
    "                convolved = G_conv(G_in, out_n)\n",
    "                output = batchnorm(convolved)\n",
    "                layers.append(output)\n",
    "\n",
    "        layer_specs = [\n",
    "#            ngf * 4,   # decoder_4\n",
    "#            ngf * 2,   # decoder_3\n",
    "            ngf,       # decoder_2\n",
    "        ]\n",
    "\n",
    "        num_encoder_layers = len(layers)\n",
    "        for decoder_layer, out_channels in enumerate(layer_specs):\n",
    "            skip_layer = num_encoder_layers - decoder_layer - 1\n",
    "            with tf.variable_scope(\"decoder_%d\" % (skip_layer + 1)):\n",
    "    #             if decoder_layer == 0:\n",
    "    #                 # first decoder layer doesn't have skip connections\n",
    "    #                 # since it is directly connected to the skip_layer\n",
    "    #                 decoder_input = layers[-1]\n",
    "    #             else:\n",
    "    #                 decoder_input = tf.concat([layers[-1], layers[skip_layer]], axis=4)\n",
    "                decoder_input = layers[-1]\n",
    "                rectified = tf.nn.relu(decoder_input)\n",
    "\n",
    "                decoder_output = G_conv_transpose(rectified, out_channels)\n",
    "\n",
    "                output = batchnorm(decoder_output)\n",
    "                \n",
    "                layers.append(output)\n",
    "\n",
    "        # decoder_1\n",
    "#         with tf.variable_scope(\"decoder_1\"):\n",
    "#             #dec_1_input = tf.concat([layers[-1], layers[0]], axis=4)\n",
    "#             dec_1_input = layers[-1]\n",
    "#             rectified = tf.nn.relu(dec_1_input)\n",
    "#             output = G_conv_transpose(rectified, G_out_channels)\n",
    "#             output = tf.tanh(output)\n",
    "#             layers.append(output)\n",
    "\n",
    "        return layers[-1]\n",
    "\n",
    "def site_discriminator(D_input):\n",
    "    with tf.variable_scope(\"site_discriminator\"):\n",
    "        n_layers = 2\n",
    "        layers = []\n",
    "\n",
    "        #D_input = tf.concat([discrim_inputs, discrim_targets], axis=4)\n",
    "\n",
    "        # layer_1:\n",
    "#        D_input = tf.expand_dims(D_input, -1)\n",
    "        with tf.variable_scope(\"layer_1\"):\n",
    "            convolved = D_conv(D_input, ndf)\n",
    "            pooled = D_max_pool(convolved)\n",
    "            rectified = lrelu(pooled, 0.1)\n",
    "            layers.append(rectified)\n",
    "\n",
    "        # layer_2:\n",
    "        # layer_3:\n",
    "        # layer_4:\n",
    "        for i in range(n_layers):\n",
    "            with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "                out_channels = ndf/(2*(i+1))\n",
    "\n",
    "                #stride = 1 if i == n_layers - 1 else 2  # last layer here has stride 1\n",
    "                convolved = D_conv(layers[-1], out_channels)\n",
    "                pooled = D_max_pool(convolved)\n",
    "                normalized = batchnorm(pooled)\n",
    "                rectified = lrelu(normalized, 0.1)\n",
    "                layers.append(rectified)\n",
    "\n",
    "        with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "            convolved = D_conv(rectified, out_channels=1)\n",
    "            fc1 = tf.contrib.layers.flatten(convolved)\n",
    "#            fc1 = tf.layers.dense(fc1, 300)\n",
    "#            fc1 = lrelu(fc1)\n",
    "            # Output layer, class prediction\n",
    "            out = tf.layers.dense(fc1, 17)\n",
    "            layers.append(out)\n",
    "    #         pred_classes = tf.argmax(out, axis=1)\n",
    "    #         layers.append(pred_classes)\n",
    "        return layers[-1]\n",
    "\n",
    "def qc_discriminator(D_input):\n",
    "    with tf.variable_scope(\"qc_discriminator\"):\n",
    "        n_layers = 2\n",
    "        layers = []\n",
    "\n",
    "    #    D_input = tf.concat([discrim_inputs, discrim_targets], axis=4)\n",
    "    #    D_input = tf.expand_dims(D_input, -1)\n",
    "\n",
    "        # layer_1:\n",
    "        with tf.variable_scope(\"layer_1\"):\n",
    "            convolved = D_conv(D_input, ndf)\n",
    "            pooled = D_max_pool(convolved)\n",
    "            rectified = lrelu(pooled, 0.1)\n",
    "            layers.append(rectified)\n",
    "\n",
    "        # layer_2:\n",
    "        # layer_3:\n",
    "        # layer_4:\n",
    "        for i in range(n_layers):\n",
    "            with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "                out_channels = ndf/(2*(i+1))\n",
    "                #stride = 1 if i == n_layers - 1 else 2  # last layer here has stride 1\n",
    "                convolved = D_conv(layers[-1], out_channels)\n",
    "                pooled = D_max_pool(convolved)\n",
    "                normalized = batchnorm(pooled)\n",
    "                rectified = lrelu(normalized, 0.1)\n",
    "                layers.append(rectified)\n",
    "\n",
    "        with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "            convolved = D_conv(rectified, out_channels=1)\n",
    "\n",
    "            fc1 = tf.contrib.layers.flatten(convolved)\n",
    "#            fc1 = tf.layers.dense(fc1, 300)\n",
    "#            fc1 = lrelu(fc1)\n",
    "            # Output layer, class prediction\n",
    "            out = tf.layers.dense(fc1, 2)\n",
    "            layers.append(out)\n",
    "    #         pred_classes = tf.argmax(out, axis=1)\n",
    "    #         layers.append(pred_classes)\n",
    "        return layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12\n",
    "ngf = 8 #number of generator filters in first conv layer\n",
    "ndf = 16 #number of discriminator filters in first conv layer\n",
    "seed = 123\n",
    "lr = 0.0001 #initial learning rate for adam\n",
    "beta1 = 0.5 #momentum term of adam\"\n",
    "\n",
    "features = tf.placeholder(np.float32, [4, 106, 128, 110])\n",
    "qc_labels = tf.placeholder(np.int32, [4])\n",
    "site_labels = tf.placeholder(np.int32, [4])\n",
    "\n",
    "with tf.variable_scope(\"generator\"):\n",
    "    debiased_channels = int(qc_labels.get_shape()[-1])\n",
    "    debiased = generator(features, debiased_channels)\n",
    "\n",
    "with tf.variable_scope(\"qc_discriminator\"):\n",
    "    qc_out = qc_discriminator(debiased)\n",
    "    x_in = tf.identity(qc_out)\n",
    "\n",
    "with tf.variable_scope(\"site_discriminator\"):\n",
    "    site_out = site_discriminator(debiased)\n",
    "    \n",
    "qc_D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'qc_discriminator')\n",
    "site_D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'site_discriminator')\n",
    "G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator') \n",
    "\n",
    "site_D_solver = tf.train.AdamOptimizer(lr, beta1)\n",
    "qc_D_solver = tf.train.AdamOptimizer(lr, beta1)\n",
    "G_solver = tf.train.AdamOptimizer(lr, beta1)\n",
    "\n",
    "with tf.name_scope(\"G_loss\"):\n",
    "    G_loss = tf.abs(tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=site_out, labels=site_labels)) - tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=qc_out, labels=qc_labels)))\n",
    "\n",
    "with tf.name_scope(\"QC_D_loss\"):\n",
    "    qc_D_loss = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=qc_out, labels=qc_labels))\n",
    "\n",
    "with tf.name_scope(\"Site_D_loss\"):\n",
    "    site_D_loss = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=site_out, labels=site_labels))\n",
    "    \n",
    "site_D_train_step = site_D_solver.minimize(site_D_loss, var_list=site_D_vars)\n",
    "qc_D_train_step = qc_D_solver.minimize(qc_D_loss, var_list=qc_D_vars)\n",
    "G_train_step = G_solver.minimize(G_loss, var_list=G_vars)\n",
    "qc_D_extra_step = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'qc_discriminator')\n",
    "site_D_extra_step = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'site_discriminator')\n",
    "G_extra_step = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source_code.data_io import Dataset_Pipeline, _get_data\n",
    "\n",
    "def run_a_gan(sess, G_train_step, G_loss,\\\n",
    "              qc_D_train_step, qc_D_loss,\\\n",
    "              site_D_train_step, site_D_loss,\\\n",
    "              G_extra_step, qc_D_extra_step, site_D_extra_step,\\\n",
    "              num_epoch=10):\n",
    "    \"\"\"Train a GAN for a certain number of epochs.\n",
    "    \n",
    "    Inputs:\n",
    "    - sess: A tf.Session that we want to use to run our data\n",
    "    - G_train_step: A training step for the Generator\n",
    "    - G_loss: Generator loss\n",
    "    - D_train_step: A training step for the Generator\n",
    "    - D_loss: Discriminator loss\n",
    "    - G_extra_step: A collection of tf.GraphKeys.UPDATE_OPS for generator\n",
    "    - D_extra_step: A collection of tf.GraphKeys.UPDATE_OPS for discriminator\n",
    "    Returns:\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "    log_dir = \"logs\"\n",
    "    current_run_subdir = os.path.join(\n",
    "        \"run_\" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "    model_dir = os.path.join(log_dir, 'dbGAN', '6012018')\n",
    "\n",
    "    ds = Dataset_Pipeline(target_shape=(106, 128, 110),\n",
    "                          n_epochs=10,\n",
    "                          train_src_folder=\"/home/smantra/finalproject/data/\",\n",
    "                          train_cache_prefix=\"/home/smantra/finalproject/cache_train/\",\n",
    "                          eval_src_folder=\"/home/smantra/finalproject/eval/\",\n",
    "                          eval_cache_prefix=\"/home/smantra/finalproject/cache_eval/\",\n",
    "                          batch_size=4\n",
    "                         )\n",
    "    train_dataset = _get_data(batch_size=ds.batch_size,\n",
    "                                  src_folder=ds.train_src_folder,\n",
    "                                  n_epochs=10,\n",
    "                                  cache_prefix=ds.train_cache_prefix,\n",
    "                                  shuffle=False,\n",
    "                                  target_shape=ds.target_shape,\n",
    "                                 )\n",
    "\n",
    "    ds_it = train_dataset.make_one_shot_iterator()\n",
    "    next_batch = ds_it.get_next()\n",
    "    \n",
    "    \n",
    "    print(\"Starting training!\")\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        for step in range(200):\n",
    "            #run a batch of data through the network\n",
    "            feats, (qc_labs, site_labs) = sess.run(next_batch, options=tf.RunOptions(\n",
    "        report_tensor_allocations_upon_oom=True))\n",
    "            num_debiased_channels = int(qc_labels.get_shape()[-1])\n",
    "            feed_dict={features: feats,\n",
    "                       qc_labels : qc_labs,\n",
    "                       site_labels : site_labs,                       \n",
    "                      }\n",
    "            devices = ['/gpu:0', '/gpu:1']\n",
    "            for d in devices:\n",
    "                with tf.device(d):\n",
    "                    _, G_loss_curr = sess.run([G_train_step, G_loss], feed_dict=feed_dict, options=tf.RunOptions(\n",
    "        report_tensor_allocations_upon_oom=True))\n",
    "                    _, qc_D_loss_curr = sess.run([qc_D_train_step, qc_D_loss], feed_dict=feed_dict, options=tf.RunOptions(\n",
    "        report_tensor_allocations_upon_oom=True))\n",
    "                    _, site_D_loss_curr = sess.run([site_D_train_step, site_D_loss], feed_dict=feed_dict, options=tf.RunOptions(\n",
    "        report_tensor_allocations_upon_oom=True))\n",
    "            if (step % 10 == 0):\n",
    "                print('Step: {}, qc_D: {:.4}, site_D: {:.4}, G:{:.4}'.format(step,qc_D_loss_curr,site_D_loss_curr,G_loss_curr))\n",
    "        # Print loss every epoch\n",
    "        print('Epoch: {}, qc_D: {:.4}, site_D: {:.4}, G:{:.4}'.format(epoch,qc_D_loss_curr,site_D_loss_curr,G_loss_curr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((),), types: (tf.string,)>\n",
      "Starting training!\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4,16,214,258,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: site_discriminator/site_discriminator/layer_1/conv3d/Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](generator/generator/decoder_1/Tanh, site_discriminator/site_discriminator/layer_1/conv3d/kernel/read)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n\n\t [[Node: G_loss/Abs/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1009_G_loss/Abs\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n\n\nCaused by op 'site_discriminator/site_discriminator/layer_1/conv3d/Conv3D', defined at:\n  File \"/home/shared/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/shared/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-354dea7b2ffa>\", line 21, in <module>\n    site_out = site_discriminator(debiased)\n  File \"<ipython-input-2-ee445b97ac89>\", line 90, in site_discriminator\n    convolved = D_conv(D_input, ndf)\n  File \"<ipython-input-2-ee445b97ac89>\", line 8, in D_conv\n    return tf.layers.conv3d(batch_input, out_channels, kernel_size=4, strides=(1, 1, 1), padding=\"same\")\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 828, in conv3d\n    return layer.apply(inputs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 717, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 168, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1361, in conv3d\n    name=name)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4,16,214,258,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: site_discriminator/site_discriminator/layer_1/conv3d/Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](generator/generator/decoder_1/Tanh, site_discriminator/site_discriminator/layer_1/conv3d/kernel/read)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n\n\t [[Node: G_loss/Abs/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1009_G_loss/Abs\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4,16,214,258,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: site_discriminator/site_discriminator/layer_1/conv3d/Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](generator/generator/decoder_1/Tanh, site_discriminator/site_discriminator/layer_1/conv3d/kernel/read)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n\n\t [[Node: G_loss/Abs/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1009_G_loss/Abs\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d8d909f1ec0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     sess.run(tf.global_variables_initializer(), options=tf.RunOptions(\n\u001b[1;32m     11\u001b[0m         report_tensor_allocations_upon_oom=True))\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mrun_a_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_train_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_loss\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0mqc_D_train_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqc_D_loss\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0msite_D_train_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite_D_loss\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0mG_extra_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqc_D_extra_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite_D_extra_step\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-cb50927d5934>\u001b[0m in \u001b[0;36mrun_a_gan\u001b[0;34m(sess, G_train_step, G_loss, qc_D_train_step, qc_D_loss, site_D_train_step, site_D_loss, G_extra_step, qc_D_extra_step, site_D_extra_step, num_epoch)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                     _, G_loss_curr = sess.run([G_train_step, G_loss], feed_dict=feed_dict, options=tf.RunOptions(\n\u001b[0;32m---> 58\u001b[0;31m         report_tensor_allocations_upon_oom=True))\n\u001b[0m\u001b[1;32m     59\u001b[0m                     _, qc_D_loss_curr = sess.run([qc_D_train_step, qc_D_loss], feed_dict=feed_dict, options=tf.RunOptions(\n\u001b[1;32m     60\u001b[0m         report_tensor_allocations_upon_oom=True))\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4,16,214,258,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: site_discriminator/site_discriminator/layer_1/conv3d/Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](generator/generator/decoder_1/Tanh, site_discriminator/site_discriminator/layer_1/conv3d/kernel/read)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n\n\t [[Node: G_loss/Abs/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1009_G_loss/Abs\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n\n\nCaused by op 'site_discriminator/site_discriminator/layer_1/conv3d/Conv3D', defined at:\n  File \"/home/shared/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/shared/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-354dea7b2ffa>\", line 21, in <module>\n    site_out = site_discriminator(debiased)\n  File \"<ipython-input-2-ee445b97ac89>\", line 90, in site_discriminator\n    convolved = D_conv(D_input, ndf)\n  File \"<ipython-input-2-ee445b97ac89>\", line 8, in D_conv\n    return tf.layers.conv3d(batch_input, out_channels, kernel_size=4, strides=(1, 1, 1), padding=\"same\")\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 828, in conv3d\n    return layer.apply(inputs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 717, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 168, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1361, in conv3d\n    name=name)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4,16,214,258,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: site_discriminator/site_discriminator/layer_1/conv3d/Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](generator/generator/decoder_1/Tanh, site_discriminator/site_discriminator/layer_1/conv3d/kernel/read)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n\n\t [[Node: G_loss/Abs/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1009_G_loss/Abs\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  748.11MiB from generator/generator/decoder_1/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from generator/generator/decoder_4/conv3d_transpose/BiasAdd-0-0-TransposeNCHWToNHWC-LayoutOptimizer\n  182.19MiB from gradients_2/generator/generator/decoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  182.19MiB from generator/generator/decoder_4/batch_normalization/batchnorm/mul_1\n  92.40MiB from generator/generator/encoder_4/conv3d/Conv3D\n  86.38MiB from gradients_2/generator/generator/encoder_4/batch_normalization/moments/SquaredDifference_grad/sub\n  86.38MiB from generator/generator/encoder_4/batch_normalization/batchnorm/mul_1\n  Remaining 6 nodes with 1.5KiB\n\n"
     ]
    }
   ],
   "source": [
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session\n",
    "devices = ['/gpu:0', '/gpu:1']\n",
    "d = devices[1]\n",
    "\n",
    "with get_session() as sess:\n",
    "    sess.run(tf.global_variables_initializer(), options=tf.RunOptions(\n",
    "        report_tensor_allocations_upon_oom=True))\n",
    "    run_a_gan(sess, G_train_step, G_loss,\\\n",
    "              qc_D_train_step, qc_D_loss,\\\n",
    "              site_D_train_step, site_D_loss,\\\n",
    "              G_extra_step, qc_D_extra_step, site_D_extra_step,\\\n",
    "              num_epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
